{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import math\n",
    "import copy\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import metrics\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataframe of dataset1, with 'malware' in class column\n",
    "# renamed to 0 and 'benign' renamed to 1\n",
    "df = pd.read_csv('dataset2.csv')\n",
    "\n",
    "# find pearson correlation for all features\n",
    "mean_class = df['class'].mean()\n",
    "column_names = df.columns\n",
    "\n",
    "sum1 = 0\n",
    "sum2 = 0\n",
    "sum3 = 0\n",
    "results = {}\n",
    "for column_name in column_names:\n",
    "    if(column_name != 'class'):\n",
    "        mean_of_attribute = df[column_name].mean(numeric_only=True)\n",
    "        sum1 = 0\n",
    "        sum2 = 0\n",
    "        sum3 = 0\n",
    "        for index, row in df.iterrows():\n",
    "            x_i = df.loc[index, column_name]\n",
    "            x_bar = mean_of_attribute\n",
    "            y_i = row['class']\n",
    "            y_bar = mean_class\n",
    "            sum1 += (x_i - x_bar)*(y_i-y_bar)\n",
    "            sum2 +=(x_i - x_bar)*(x_i - x_bar)\n",
    "            sum3+=(y_i-y_bar)*(y_i-y_bar)\n",
    "        if sum2*sum3 == 0:\n",
    "            correlation = 0\n",
    "        else:\n",
    "            correlation = sum1/(math.sqrt(sum2*sum3))\n",
    "        results[column_name] = correlation\n",
    "#sorted in increasing order\n",
    "results = dict(sorted(results.items(), key=lambda item: item[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set with all features saved, feature vector size: 214 (after \n",
    "# taking out class feature from original 216)\n",
    "result_set_1=df.drop('class', axis=1)\n",
    "result_set_1=result_set_1.drop('TelephonyManager.getSimCountryIso', axis=1)\n",
    "results_copy = copy.deepcopy(results)\n",
    "results_iter = copy.deepcopy(results)\n",
    "\n",
    "# correlation threshold >= 0.1, feature vector size: 39\n",
    "result_set_2 = result_set_1.copy()\n",
    "for feature in results_iter:\n",
    "    if results_iter[feature] < 0.05:\n",
    "        del results_copy[feature]\n",
    "        result_set_2.drop(feature, axis=1, inplace=True)\n",
    "\n",
    "results_iter = copy.deepcopy(results_copy)\n",
    "# correlation threshold >= 0.1, feature vector size: 27\n",
    "result_set_3 = result_set_2.copy()\n",
    "for feature in results_iter:\n",
    "    if results_iter[feature] < 0.1:\n",
    "        del results_copy[feature]\n",
    "        result_set_3.drop(feature, axis=1, inplace=True)\n",
    "\n",
    "results_iter = copy.deepcopy(results_copy)\n",
    "# correlation threshold >= 0.2, feature vector size: 14\n",
    "result_set_4 = result_set_3.copy()\n",
    "for feature in results_iter:\n",
    "    if results_iter[feature] < 0.2:\n",
    "        del results_copy[feature]\n",
    "        result_set_4.drop(feature, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfrom sklearn.model_selection import GridSearchCV\\nfrom sklearn.model_selection import ShuffleSplit\\nX = result_set_1\\ny = df['class']\\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0, stratify = y)\\nscaler = StandardScaler()\\nX_train = scaler.fit_transform(X_train)\\nX_test = scaler.transform(X_test)\\nsvc=SVC(C=10, gamma =0.1)\\nsvc.fit(X_train,y_train)\\ny_pred=svc.predict(X_test)\\ny_train_pred = svc.predict(X_train)\\nparam_grid = {'C': [0.1, 1, 10, 100, 1000], \\n              'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\\n              'degree': [2,3,4,5],\\n              'kernel': ['rbf', 'linear','sigmoid', 'poly']} \\n\\ngrid = GridSearchCV(SVC(), param_grid, refit = True, verbose = 2, cv = 2, n_jobs=-1)\\n  \\n# fitting the model for grid search\\ngrid.fit(X_train, y_train)\\nprint(grid.best_params_)\\n\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# COMMENTED OUT, only needs to run once + very computationally expensive\n",
    "# runs GridSearch with cross-fold val. = 2, full feature set, split rate 0.2\n",
    "\"\"\"\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "X = result_set_1\n",
    "y = df['class']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0, stratify = y)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "svc=SVC(C=10, gamma =0.1)\n",
    "svc.fit(X_train,y_train)\n",
    "y_pred=svc.predict(X_test)\n",
    "y_train_pred = svc.predict(X_train)\n",
    "param_grid = {'C': [0.1, 1, 10, 100, 1000], \n",
    "              'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
    "              'degree': [2,3,4,5],\n",
    "              'kernel': ['rbf', 'linear','sigmoid', 'poly']} \n",
    "\n",
    "grid = GridSearchCV(SVC(), param_grid, refit = True, verbose = 2, cv = 2, n_jobs=-1)\n",
    "  \n",
    "# fitting the model for grid search\n",
    "grid.fit(X_train, y_train)\n",
    "print(grid.best_params_)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result Set 1\n",
      " Evaluating classifier on test data ...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96      1896\n",
      "           1       1.00      0.85      0.92      1112\n",
      "\n",
      "    accuracy                           0.94      3008\n",
      "   macro avg       0.96      0.92      0.94      3008\n",
      "weighted avg       0.95      0.94      0.94      3008\n",
      "\n",
      "Validation Accuracy: 0.9438164893617021\n",
      "Training Accuracy: 0.9990023279015631\n",
      "Result Set 2\n",
      " Evaluating classifier on test data ...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.97      0.96      1896\n",
      "           1       0.95      0.90      0.93      1112\n",
      "\n",
      "    accuracy                           0.95      3008\n",
      "   macro avg       0.95      0.94      0.94      3008\n",
      "weighted avg       0.95      0.95      0.95      3008\n",
      "\n",
      "Validation Accuracy: 0.9461436170212766\n",
      "Training Accuracy: 0.9666611240438976\n",
      "Result Set 3\n",
      " Evaluating classifier on test data ...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.97      0.95      1896\n",
      "           1       0.95      0.88      0.91      1112\n",
      "\n",
      "    accuracy                           0.94      3008\n",
      "   macro avg       0.94      0.92      0.93      3008\n",
      "weighted avg       0.94      0.94      0.94      3008\n",
      "\n",
      "Validation Accuracy: 0.9375\n",
      "Training Accuracy: 0.9556867309610908\n",
      "Result Set 4\n",
      " Evaluating classifier on test data ...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.93      0.92      1896\n",
      "           1       0.88      0.83      0.85      1112\n",
      "\n",
      "    accuracy                           0.89      3008\n",
      "   macro avg       0.89      0.88      0.88      3008\n",
      "weighted avg       0.89      0.89      0.89      3008\n",
      "\n",
      "Validation Accuracy: 0.8932845744680851\n",
      "Training Accuracy: 0.9039740605254406\n"
     ]
    }
   ],
   "source": [
    "# varying feature sets with a constant split rate of 0.2\n",
    "result_sets = [result_set_1, result_set_2, result_set_3,result_set_4] \n",
    "for i, X in enumerate(result_sets):\n",
    "    # create the classifier\n",
    "    y = df['class']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0, stratify = y)\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    svc=SVC(C=10, gamma =0.1)\n",
    "    svc.fit(X_train,y_train)\n",
    "    y_pred=svc.predict(X_test)\n",
    "    y_train_pred = svc.predict(X_train)\n",
    "\n",
    "    # log results\n",
    "    print(\"Result Set\",i+1)\n",
    "    print(\" Evaluating classifier on test data ...\")\n",
    "    print(metrics.classification_report(y_test, y_pred))\n",
    "    print(\"Validation Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
    "    print(\"Training Accuracy:\",metrics.accuracy_score(y_train, y_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result Set 1.2\n",
      " Evaluating classifier on test data ...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.97      0.96      1896\n",
      "           1       0.95      0.90      0.93      1112\n",
      "\n",
      "    accuracy                           0.95      3008\n",
      "   macro avg       0.95      0.94      0.94      3008\n",
      "weighted avg       0.95      0.95      0.95      3008\n",
      "\n",
      "Validation Accuracy: 0.9461436170212766\n",
      "Training Accuracy: 0.9666611240438976\n",
      "Result Set 1.25\n",
      " Evaluating classifier on test data ...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96      2369\n",
      "           1       0.95      0.90      0.93      1390\n",
      "\n",
      "    accuracy                           0.95      3759\n",
      "   macro avg       0.95      0.94      0.94      3759\n",
      "weighted avg       0.95      0.95      0.95      3759\n",
      "\n",
      "Validation Accuracy: 0.9481245011971269\n",
      "Training Accuracy: 0.9663917708610446\n",
      "Result Set 1.3\n",
      " Evaluating classifier on test data ...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.98      0.96      2843\n",
      "           1       0.96      0.90      0.93      1668\n",
      "\n",
      "    accuracy                           0.95      4511\n",
      "   macro avg       0.95      0.94      0.94      4511\n",
      "weighted avg       0.95      0.95      0.95      4511\n",
      "\n",
      "Validation Accuracy: 0.9487918421636001\n",
      "Training Accuracy: 0.9665558194774346\n"
     ]
    }
   ],
   "source": [
    "# varying split rate with a constant feature set of vector size 39\n",
    "split_rate = [0.2, 0.25, 0.3] \n",
    "for i in split_rate:\n",
    "    # create the classifier\n",
    "    X = result_set_2\n",
    "    y = df['class']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = i, random_state = 0, stratify = y)\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    svc=SVC(C=10, gamma =0.1)\n",
    "    svc.fit(X_train,y_train)\n",
    "    y_pred=svc.predict(X_test)\n",
    "    y_train_pred = svc.predict(X_train)\n",
    "\n",
    "    # log results\n",
    "    print(\"Result Set\", i+1)\n",
    "    print(\" Evaluating classifier on test data ...\")\n",
    "    print(metrics.classification_report(y_test, y_pred))\n",
    "    print(\"Validation Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
    "    print(\"Training Accuracy:\",metrics.accuracy_score(y_train, y_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['transact', 'onServiceConnected', 'bindService', 'attachInterface',\n",
      "       'ServiceConnection', 'android.os.Binder', 'SEND_SMS',\n",
      "       'Ljava.lang.Class.getCanonicalName', 'Ljava.lang.Class.getMethods',\n",
      "       'Ljava.lang.Class.cast',\n",
      "       ...\n",
      "       'SET_ORIENTATION', 'READ_CONTACTS', 'DEVICE_POWER', 'HARDWARE_TEST',\n",
      "       'ACCESS_WIFI_STATE', 'WRITE_EXTERNAL_STORAGE', 'ACCESS_FINE_LOCATION',\n",
      "       'SET_WALLPAPER_HINTS', 'SET_PREFERRED_APPLICATIONS',\n",
      "       'WRITE_SECURE_SETTINGS'],\n",
      "      dtype='object', length=214)\n",
      "14\n",
      "27\n",
      "39\n"
     ]
    }
   ],
   "source": [
    "random.seed(0)\n",
    "# creating list of all 215 features corresponding to an index\n",
    "feature_vector_ordered = []\n",
    "for feature in results:\n",
    "    # ignore because it had a NaN correlation value\n",
    "    if feature != \"TelephonyManager.getSimCountryIso\":\n",
    "        feature_vector_ordered.append(feature)\n",
    "# skipping random_feature_set_1 because the other result_set_1 corresponds\n",
    "# to the original set of feature vectors\n",
    "# the randomized 5 sets that will hold 39 features\n",
    "random_set_2_1 = result_set_1.copy()\n",
    "random_set_2_2 = result_set_1.copy()\n",
    "random_set_2_3 = result_set_1.copy()\n",
    "random_set_2_4 = result_set_1.copy()\n",
    "random_set_2_5 = result_set_1.copy()\n",
    "random_feature_set_2 = [random_set_2_1, random_set_2_2, random_set_2_3, random_set_2_4, random_set_2_5]\n",
    "# the randomized 5 sets that will hold 27 features\n",
    "random_set_3_1 = result_set_1.copy()\n",
    "random_set_3_2 = result_set_1.copy()\n",
    "random_set_3_3 = result_set_1.copy()\n",
    "random_set_3_4 = result_set_1.copy()\n",
    "random_set_3_5 = result_set_1.copy()\n",
    "random_feature_set_3 = [random_set_3_1, random_set_3_2, random_set_3_3, random_set_3_4, random_set_3_5]\n",
    "# the randomized 5 sets that will hold 24 features\n",
    "random_set_4_1 = result_set_1.copy()\n",
    "random_set_4_2 = result_set_1.copy()\n",
    "random_set_4_3 = result_set_1.copy()\n",
    "random_set_4_4 = result_set_1.copy()\n",
    "random_set_4_5 = result_set_1.copy(4)\n",
    "random_feature_set_4 = [random_set_4_1, random_set_4_2, random_set_4_3, random_set_4_4, random_set_4_5]\n",
    "# randomly select the appropriate number of features for each subset, so that each \n",
    "# random_feature_set holds 5 subsets of randomly selected features\n",
    "random_set = [random_feature_set_2, random_feature_set_3, random_feature_set_4]\n",
    "num_features_to_drop = [175, 187, 200]\n",
    "i = 0\n",
    "for rs in random_set:\n",
    "    for random_subset in rs:\n",
    "        dropped_features = []\n",
    "        while len(dropped_features) < num_features_to_drop[i]:\n",
    "            rand_num = random.randint(1, 214) - 1\n",
    "            if rand_num not in dropped_features:\n",
    "                random_subset.drop(feature_vector_ordered[rand_num], axis=1, inplace=True)\n",
    "                dropped_features.append(rand_num)\n",
    "    i+=1\n",
    "print(len(random_set_4_4.columns))\n",
    "print(len(random_set_3_4.columns))\n",
    "print(len(random_set_2_4.columns))\n",
    "# for each feature vector size (27, 24, 21, 14) use the randomly chosen feature subsets\n",
    "# (five for each vector size) and average the results\n",
    "count = 1\n",
    "for rs in random_set:\n",
    "    avg_weighted_precision = 0\n",
    "    avg_weighted_f1 = 0\n",
    "    avg_weighted_recall = 0\n",
    "    avg_accuracy = 0\n",
    "    avg_tacc = 0\n",
    "    avg_vacc = 0\n",
    "    for i, X in enumerate(rs):\n",
    "        # create the classifier\n",
    "        y = df['class']\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0, stratify = y)\n",
    "        scaler = StandardScaler()\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "        svc=SVC(C=10, gamma =0.1)\n",
    "        svc.fit(X_train,y_train)\n",
    "        y_pred=svc.predict(X_test)\n",
    "        y_train_pred = svc.predict(X_train)\n",
    "        report = metrics.classification_report(y_test, y_pred,output_dict=True)\n",
    "        avg_weighted_precision += report['weighted avg']['precision'] \n",
    "        avg_weighted_f1 += report['weighted avg']['f1-score'] \n",
    "        avg_accuracy += report['accuracy']\n",
    "        avg_weighted_recall += report['weighted avg']['recall'] \n",
    "        avg_tacc += metrics.accuracy_score(y_test, y_pred)\n",
    "        avg_vacc += metrics.accuracy_score(y_train, y_train_pred)\n",
    "    avg_weighted_precision /= 5\n",
    "    avg_weighted_f1 /= 5\n",
    "    avg_weighted_recall /= 5\n",
    "    avg_accuracy /= 5\n",
    "    avg_tacc /= 5\n",
    "    avg_vacc /= 5\n",
    "    print(\"Random set\", count)\n",
    "    print(\"Average weighted precision:\",avg_weighted_precision)\n",
    "    print(\"Average weighted F1-score:\",avg_weighted_f1)\n",
    "    print(\"Average weighted recall:\",avg_weighted_recall)\n",
    "    print(\"Average accuracy:\",avg_accuracy)\n",
    "    print(\"Average T.acc%:\",avg_tacc)\n",
    "    print(\"Average V.acc%:\",avg_vacc)\n",
    "    count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
